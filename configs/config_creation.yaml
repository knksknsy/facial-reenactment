# Default settings

device: cuda
pin_memory: false                                 # if true: 'device' must be set to 'cpu'
num_workers: 4                                    # >0: faster data loading, increased GPU usage

paths:
  log_dir: /home/kaan/facial-reenactment/logs
  checkpoint_dir: /home/kaan/facial-reenactment/checkpoints
  gen_dir: /home/kaan/facial-reenactment/generated_train
  gen_test_dir: /home/kaan/facial-reenactment/generated_test
  output_dir: /home/kaan/facial-reenactment/outputs

dataset:
  dataset_train: /home/kaan/datasets/VoxCeleb2/CropIdsPreprocessed/dev/
  dataset_test: /home/kaan/datasets/VoxCeleb2/CropIdsPreprocessed/test/
  csv_train: ./csv/voxceleb_crop_ids_dev.csv
  csv_test: ./csv/voxceleb_crop_test.csv
  image_size: 128
  channels: 3
  normalize: [0.5,0.5]                            # input normalization: [mean:0.5,std:0.5] -> min:-1;max:1
  shuffle: true                                   # DataLoader: shuffle data
  augmentation:
    horizontal_flip: true                         # if true: randomly flip data
    rotation_angle: 15                            # >0: randomly rotate data

train:
  test: true                                      # test model after each epoch
  metrics: false                                  # calculate evaluation metrics during training
  continue_id: null
  seed: 57
  epochs: 30
  batch_size: 8
  iterations: 5000                                # limit iterations per epoch; 0: no limit, >0: limit; 5,000/batch_size 
  log_freq: 1000                                  # frequency [iterations] to log generated images
  landmark_type: boundary                         # 'boundary' or 'keypoint'
  vgg_type: vgg16                                 # vgg16 or vggface
  conv_blocks_d: 4                                # number of conv blocks in discriminator: 4 or 6
  spec_norm: false                                # use spectral normalization
  update_strategy:
    d_iters: 5                                    # fixed update strategy: wgan-gp: d_iters=5, else: d_iters=2
    loss_coeff: 5                                 # >0: use adaptive update strategy; =0: use fixed update strategy; will start with fixed stategy then adaptive
  grad_clip: 1                                    # use gradient clipping
  loss_weights:
    l_adv: 1
    l_rec: 10
    l_self: 100
    l_triple: 100
    l_id: 1
    l_percep: 10
    l_fm: 10
    l_tv: 1.0e-4
    l_gp: 10                                      # >0: gradient penalty mode
    l_gc: 0                                       # >0: gradient clipping mode
  optimizer:
    overwrite_optim: false                        # false: settings from checkpoints optimizer will be used; true: overwrite settings
    lr_g: 1.0e-4
    lr_d: 1.0e-4
    beta1: 0.5
    beta2: 0.999
    weight_decay: 5.0e-4
    # lr_linear_decay:                              # linear learning rate schedule
    #   epoch_range: [0, 19]                        # modify learning rate from epoch 1 to 20
    #   lr_g_end: 1.0e-6
    #   lr_d_end: 1.0e-6
    # lr_step_decay:                                # step based learning rate schedule
    #   step_size: 10                               # decay learning rate every epoch = step_size
    #   gamma: 0.1                                  # decay learning rate by: lr = lr * gamma
    lr_plateau_decay:                             # plateau based learning rate schedule: see torch.optim.lr_scheduler.ReduceLROnPlateau
      plateau_mode: 'min'
      plateau_factor: 0.1
      plateau_patience: 10
      plateau_min_lr_g: 1.0e-6
      plateau_min_lr_d: 1.0e-6

test:
  batch_size_test: 32
  shuffle_test: true                             # shuffle DataLoader during testing
  log_freq_test: 10
  num_workers_test: 2
  tag_prefix: 'Test'

logs:
  overwrite_csv: false
  overwrite_plot: true
  overwrite_video: true
  v_img_source: /home/kaan/datasets/VoxCeleb2/CropIdsPreprocessed/test/id00017/5MkXgwdrmJw/1.png
  v_vid_target: /home/kaan/datasets/VoxCeleb2/Videos/test/id01567/1Lx_ZqrK1bM/00001.mp4

preprocessing:
  num_pairs: 3                                    # number of training pairs (frames) to extract from a video
  max_frames: 66                                  # number of max frames to extract from a video
  num_videos: 0                                   # >0: number of videos to be preprocessed, =0: all videos
  padding: 10
  padding_color: [111, 108, 112]
  image_size_db: 224
  overwrite_videos: false
  prune_videos: false
