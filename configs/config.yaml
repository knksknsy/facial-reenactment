# Default settings

device: cuda
device_options: [cuda, cpu]
pin_memory: false                                 # if true: 'device' must be set to 'cpu'
num_workers: 4                                    # >0: faster data loading, increased GPU usage

paths:
  log_dir: /media/Alpha/facial-reenactment/logs
  checkpoint_dir: /media/Alpha/facial-reenactment/checkpoints
  gen_dir: /media/Alpha/facial-reenactment/generated_train
  gen_test_dir: /media/Alpha/facial-reenactment/generated_test
  output_dir: /media/Alpha/facial-reenactment/outputs

dataset:
  dataset_train: /home/kaan/datasets/VoxCeleb2/IdsPreprocessed/dev/
  dataset_test: /home/kaan/datasets/VoxCeleb2/Preprocessed/test/
  csv_train: ./dataset/dataset_ids_dev.csv
  csv_test: ./dataset/dataset_test.csv
  image_size: 64
  channels: 1
  shuffle: true                                   # DataLoader: shuffle data
  augmentation:
    shuffle_frames: false                         # if true: randomly select 3 frames out of 'num_frames' 
    horizontal_flip: true                         # if true: randomly flip data
    rotation_angle: 15                            # >0: randomly rotate data

train:
  test: true                                      # test model after each epoch
  continue_id: null                               # continue training from checkpoint
  precision: 16                                   # 16 or 32 bit
  seed: 57
  epochs: 30
  batch_size: 8
  checkpoint_freq: 5000                           # frequency [iterations] to save checkpoints
  log_freq: 1000                                  # frequency [iterations] to log generated images
  gan_type: wgan-gp
  landmark_type: 'boundary'                       # 'boundary' or 'keypoint'
  update_strategy:
    d_iters: 5                                    # fixed update strategy
    loss_coeff: 1                                 # >0: use adaptive update strategy; =0: use fixed update strategy; will start with fixed stategy then adaptive
  grad_clip: 1                                    # use gradient clipping
  loss_weights:
    l_adv: 1
    l_rec: 10
    l_self: 100
    l_triple: 100
    l_percep: 10
    l_tv: 1.0e-4
    l_gp: 10
  optimizer:
    overwrite_optim: false                        # false: settings from checkpoints optimizer will be used; true: overwrite settings
    lr_g: 1.0e-4
    lr_d: 4.0e-4
    beta1: 0.5
    beta2: 0.9
    weight_decay: 5.0e-4
    lr_decay:
      epoch_range: [0, 19]                        # modify learning rate from epoch 1 to 20
      lr_g_end: 1.0e-6
      lr_d_end: 4.0e-6

test:
  batch_size_test: 8

preprocessing:
  num_pairs: 3                                    # number of training pairs (frames) to extract from a video
  max_frames: 66                                  # number of max frames to extract from a video
  num_videos: 0                                   # >0: number of videos to be preprocessed, =0: all videos
  padding: 10
  padding_color: [111, 108, 112]
  image_size_db: 224
  overwrite_videos: false
  prune_videos: false