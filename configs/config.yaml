# Default settings

device: cuda
device_options: [cuda, cpu]
pin_memory: false                                 # if true: 'device' must be set to 'cpu'
num_workers: 4                                    # >0: faster data loading, increased GPU usage

paths:
  log_dir: /media/Alpha/facial-reenactment/logs
  checkpoint_dir: /media/Alpha/facial-reenactment/checkpoints
  gen_dir: /media/Alpha/facial-reenactment/generated_train
  gen_test_dir: /media/Alpha/facial-reenactment/generated_test
  output_dir: /media/Alpha/facial-reenactment/outputs

preprocessing:
  num_frames: 8                                   # number of frames +1 to extract from a video
  num_videos: 0                                   # >0: number of videos to be preprocessed, =0: all videos
  overwrite_videos: false

dataset:
  dataset_train: /home/kaan/datasets/VoxCeleb2/Preprocessed/dev/
  dataset_test: /home/kaan/datasets/VoxCeleb2/Preprocessed/test/
  csv_train: ./dataset/dataset_dev.csv
  csv_test: ./dataset/dataset_test.csv
  image_size: 128
  shuffle: true                                   # DataLoader: shuffle data
  augmentation:
    shuffle_frames: true                          # if true: randomly select 3 frames out of 'num_frames' 
    horizontal_flip: true                         # if true: randomly flip data
    rotation_angle: 15                            # >0: randomly rotate data

train:
  test: false                                     # test model after each epoch
  continue_id: null                               # continue training from checkpoint
  seed: 57
  epochs: 30
  batch_size: 8
  lr_g: 1.0e-4
  lr_d: 4.0e-4
  checkpoint_freq: 5000                           # frequency [iterations] to save checkpoints
  log_freq: 1000                                  # frequency [iterations] to log generated images
  gan_type: wgan-gp
  update_strategy:
    d_iters: 5                                    # fixed update strategy
    loss_coeff: 1                                 # >0: use adaptive update strategy; =0: use fixed update strategy; will start with fixed stategy then adaptive
  grad_clip: 1                                    # use gradient clipping
  loss_weights:
    l_adv: 1
    l_rec: 10
    l_self: 100
    l_triple: 100
    l_percep: 10
    l_tv: 1.0e-4
    l_gp: 10
    l_mask: 1
    l_mask_smooth: 1.0e-4
  optimizer:
    overwrite_optim: true                         # true: settings from checkpoints optimizer will be used; false: overwrite settings
    beta1: 0.5
    beta2: 0.9
    weight_decay: 5.0e-4
    scheduler_epoch_range: [0, 19]                # modify learning rate from epoch 1 to 20
    scheduler_lr_g_end: 1.0e-6
    scheduler_lr_d_end: 4.0e-6

test:
  batch_size_test: 1
